import re
import nltk
import statistics
from nltk.translate.bleu_score import sentence_bleu, corpus_bleu
import nltk.translate.gleu_score as gleu
import pandas as pd
import syllables
from nltk.tokenize import sent_tokenize
import torch
from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoConfig, AutoModelWithLMHead, \
    AutoModelForPreTraining
from difflib import SequenceMatcher
import itertools
import spacy

# Define model name, length of the tokenizer and special tokenizers


def myTokenizer(model="gpt2", special_tokens=None):
    tokenizer = AutoTokenizer.from_pretrained(model)
    tokenizer.add_special_tokens(special_tokens)
    return tokenizer


# the function creates a pandas dataframe from a file whose filepath is passed as argument
def create_df(filepath):
    with open(filepath, "r") as f:
        data = f.read()
        # replace the endline
        data = data.replace("\n", "")
        # split data according to end review token
        d = data.split(' <OVERV_END>')
        for element in d:
            pass
        # create dataframe with the 'Description' column, meanwhile dropping NA rows
        df = pd.DataFrame(d, columns=['Description']).dropna()
        df = df.drop([len(df.index) - 1])
        return df


# This function splits the input pandas Dataframe to greater columns:
# (Description, OriginalInput) -> (OriginalInput, input, title, Description)
def adapt_df(df):
    df['originalInput'] = df['Description'].apply(extract_info)
    df['input'] = df['originalInput'].apply(extract_input)
    df['title'] = df['originalInput'].apply(extract_title)
    df['Description'] = df['Description'].apply(extract_text)
    return df


# Extracts the title and features of the product with the tokens
def extract_info(text):
    return text.split(' <DESCR_START>')[0]


# Extract all the features of the product without the tokens
def extract_input(text):
    res = re.findall("<FEAT_START> (.*?) <FEAT_END>", text)
    return res[0].replace("<NEXT_FEAT>", "<br>").replace("br><h2>", "").replace("</li><li>", "")


# Extract the title of the product without the tokens
def extract_title(text):
    res = re.findall("<NAME_START> (.*?) <NAME_END>", text)
    return res[0]


# Extract the description of the product
def extract_text(text):
    res = re.findall("<DESCR_START> (.*?) <DESCR_END>", text)
    return res[0]


stopwords = nltk.corpus.stopwords.words('english')
# blacklist=["battery","pocket","carry","purse","ergonomic"]
blacklist = []
nlp = spacy.load('en_core_web_sm')


# Define a new class of function which is used to process the text generated by the GPT2 module
class ProcessRev():
    def __init__(self):
        pass

    # this function can be removed -> only defined but not used
    def process_hidden_title(self, text):
        doc = nlp(text)
        sub_toks = [tok for tok in doc if (tok.dep_ == "nsubj")]
        for noun in sub_toks:
            if str(noun).istitle():
                title = text.split(str(noun))[0].split('. ')[-1] + str(noun)
                title2 = ". " + text.split(str(noun))[0].split('. ')[-1] + str(noun) + "."
                word_list = title.split()
                number_of_words = len(word_list)
                if number_of_words > 1:
                    text = text.replace(title, title2).replace(". .", "..")
        return text

    # returns the similarity defined by SequenceMatcher
    def similar(self, a, b):
        return SequenceMatcher(None, a, b).ratio()

    # can be removed since only defined but not used
    def find_title(self, mylist):
        for i in range(len(mylist) - 1):
            if mylist[i] == '' and mylist[i + 1].istitle():
                mylist[i + 1] = "\n\n####{}\n\n".format(mylist[i + 1])
        for e in mylist:
            if e == '':
                mylist.remove(e)
        return mylist

    # From a list of sentence(mylist),
    def find_title2(self, mylist):
        for i in range(len(mylist)):
            temp_list = []
            # split each sentence into word lever
            for word in mylist[i].split():
                # if the word is not a stopword (loaded from nltk library)
                if word.lower() not in stopwords:
                    # add the word to the temporary list
                    temp_list.append(word)
            # combine the words
            title = (' '.join(temp_list))
            # if the combined words is formed by uppercases -> it is a title
            if title.istitle():
                # add extra formatting for the title
                mylist[i] = "\n\n#### {}\n\n".format(mylist[i])
        return mylist

    def filter_black(self, mylist):
        for e in mylist:
            for black in blacklist:
                if e.lower().find(black) != -1:
                    try:
                        mylist.remove(e)
                    except:
                        pass
        return mylist

    def clean_review(self, review):
        # simple processing of the review
        review = review.replace("</h2>  <br>", "</h2> <br> ").replace("..", ".")
        # split the review in sentences based on the sent_tokenize function
        tmp_list = nltk.sent_tokenize(review)
        # remove the last element of each sentence (usually the dot)
        for i in range(len(tmp_list)):
            tmp_list[i] = tmp_list[i][:-1]

        # tmp_list=list(review.split('.'))
        # del tmp_list[-1:]
        # tmp_list=self.filter_black(tmp_list)

        tmp_list = list(dict.fromkeys(tmp_list))
        # add extra formatting to the titles (with various 'newline' and 'hashtags')
        tmp_list = self.find_title2(tmp_list)
        # for a and b sentences formed by combination of 2 elements of the sentence list
        for a, b in itertools.combinations(tmp_list, 2):
            # if both a and b are not title, and their similarity is very high
            if a.find('#') == -1 and b.find('#') == -1 and self.similar(a, b) > 0.9:
                try:
                    # remove the sentence from the list
                    tmp_list.remove(b)
                except:
                    pass

        # restore the result by concatenating all the sentences with the dot (since it was removed previously)
        result = tmp_list[0]
        for i in range(1, len(tmp_list)):
            # careful in not adding the title
            if tmp_list[i - 1].find("#") == -1:
                result = result + ". " + tmp_list[i]
            else:
                # concatenate the title(since there were already 'newline' and 'hashtags', we don't need to add more puntuaction)
                result = result + tmp_list[i]

        # add the final dot
        result = result + "."

        # remove all the <h2>s and additional spaces
        l = re.findall("<h2> (.*?) </h2>", result)
        for a, b in itertools.combinations(l, 2):
            result = result.replace("<br><h2> " + b + " </h2>", "").replace("   ", " ")
        return result


# This Class is used to evaluate the performance of the GPT2 model
class Tester:
    def __init__(self, df, model, tokenizer):
        self.df = df
        self.model = model
        self.tokenizer = tokenizer
       

    # wrapper function that generates the review with the GPT2 module
    # with the specific parameters of
    # temperature
    # top_k
    # top_p
    # (parameters are described in the module explanation)
    def generate(self, temp=.75, k=35, p=0.95):
        for index, row in self.df.iterrows():
            print("Generating: " + str(index))
            res = self.generate_text(row.originalInput, row.Description, temp, k, p)
            try:
                for key in res:
                    self.df.loc[index, key] = res[key]
            except:
                pass
        return self.df

    # function that calls the GPT2 model to generate the function and compute
    # the various metrics (greater detail present in the module explanation)
    def generate_text(self, input_text, ref, temp, k, p):
        inputs = self.tokenizer.encode(input_text, return_tensors='pt').to("cuda:0")  # gpu usage
        outputs = self.model.generate(inputs, max_length=768,
                                 do_sample=True,
                                 # num_beams=8,
                                 temperature=temp,
                                 # repetition_penalty=1.2,
                                 top_k=k,
                                 top_p=p,
                                 # no_repeat_ngram_size=3,
                                 early_stopping=True,
                                 # num_beam_groups=2,
                                 # diversity_penalty=12.0,
                                 num_return_sequences=3)

        # compute the metrics for the evaluation
        res_dict = self.evaluate_bleu(ref, outputs)
        return res_dict

    def evaluate_bleu(self, ref, outputs):
        bleu_list = []
        gleu_list = []
        gleu_list_clean = []
        bleu_list_clean = []
        Flesch_list = []  # Computes the Flech reading ease score. ranges from 1 to 100. The bigger the score the easier is to read -> suitable for low informated public
        Coleman_list = []  # computes the Coleman-Liau index, ranges from 6 to 19. The lower the score the lower the education level -> suitable for low ed level public
        Gunning_list = []  # Computes the Gunning Fog index, ranges from 6 to 17. The lower the score the lower the education level -> suitable for low ed level public

        flag = False
        for rev in outputs:
            try:
                predicted = tokenizer.decode(rev, skip_special_tokens=False)
                output = predicted.partition("<|PAD|>")[0]
                review = str(re.search('<DESCR_START>(.*)<DESCR_END>', output).group(1))
                try:
                    review_clean = ProcessRev().clean_review(review)
                except:
                    review_clean = review
                if flag is False:
                    final_rew = review
                    final_rew_clean = review_clean
                    flag = True
                l = len(ref.split())
                t = review.split()[:l]
                text = ' '.join(t)
                t_c = review_clean.split()[:l]
                text_clean = ' '.join(t_c)
                bleu_list.append(sentence_bleu([ref], text))
                gleu_list.append(gleu.sentence_gleu([ref], text))
                bleu_list_clean.append(sentence_bleu([ref], text_clean))
                gleu_list_clean.append(gleu.sentence_gleu([ref], text_clean))

                text = text.replace('<h2>', '').replace('</h2>', '').replace('<br>', '').strip().lower()
                text = re.sub("\s\s+", " ", text)

                # compute Flesch_score
                tot_words = len(text.split())
                tot_syllabus = syllables.estimate(text)
                tot_sentences = len(sent_tokenize(text))
                Flesch_score = 206.835 - 1.015 * (tot_words / tot_sentences) - 84.6 * (tot_syllabus / tot_words)
                Flesch_list.append(Flesch_score)

                # compute Coleman-Liau index
                # avg number of letters per 100 words
                tot_letters = len(text)
                avg_letters = (tot_letters / tot_words) * 100
                # avg number of sentence per 100 words
                avg_sentences = (tot_sentences / tot_words) * 100
                Coleman_score = 0.05888 * avg_letters - 0.269 * avg_sentences - 15.8
                Coleman_list.append(Coleman_score)

                # compute Gunning Fog index
                new_words = text.split()[:100]
                complex_word = 0
                for word in new_words:
                    if word[0].isupper() == False:
                        if syllables.estimate(word) > 2:
                            complex_word += 1
                n_words = len(new_words)
                new_text = ' '.join(new_words)
                n_sentences = len(sent_tokenize(new_text))
                Gunning_score = 0.4 * ((n_words / n_sentences) + 100 * (complex_word / n_words))
                Gunning_list.append(Gunning_score)



            except:
                pass

        # return {'review':final_rew,'review_clean':final_rew_clean,'bleu_mean':statistics.mean(bleu_list),'bleu_std':statistics.stdev(bleu_list),'bleu_clean_mean':statistics.mean(bleu_list_clean),'bleu_clean_std':statistics.stdev(bleu_list_clean),'gleu_mean':statistics.mean(gleu_list),'gleu_std':statistics.stdev(gleu_list),'gleu_clean_mean':statistics.mean(gleu_list_clean),'gleu_clean_std':statistics.stdev(gleu_list_clean)}
        try:
            return {'review': final_rew, 'review_clean': final_rew_clean,
                    'bleu_mean': statistics.mean(bleu_list), 'bleu_std': statistics.stdev(bleu_list),
                    'bleu_clean_mean': statistics.mean(bleu_list_clean),
                    'bleu_clean_std': statistics.stdev(bleu_list_clean),
                    'gleu_mean': statistics.mean(gleu_list), 'gleu_std': statistics.stdev(gleu_list),
                    'gleu_clean_mean': statistics.mean(gleu_list_clean),
                    'gleu_clean_std': statistics.stdev(gleu_list_clean),
                    'flesch_mean': statistics.mean(Flesch_list), 'flesch_std': statistics.stdev(Flesch_list),
                    'coleman_mean': statistics.mean(Coleman_list), 'coleman_std': statistics.stdev(Coleman_list),
                    'gunning_mean': statistics.mean(Gunning_list), 'gunning_std': statistics.stdev(Gunning_list), }
        except:
            pass